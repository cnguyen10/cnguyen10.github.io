<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2020-12-26">

<title>Cuong Nguyen - PAC-Bayes bounds for generalisation error</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../robot.svg" rel="icon" type="image/svg+xml">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NLRVZL0JSR"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-NLRVZL0JSR', { 'anonymize_ip': true});
</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<script>
  window.onload = async function() {
    var options = {
      indentSize: '1.2em',
      commentDelimiter: '\u00A0\u00A0\u00A0\u00A0\u00A0 \u25B9 \u0020',
      lineNumber: true,
      lineNumberPunc: ':',
      noEnd: false,
      captionCount: undefined
    };
    pseudocode.renderClass("pseudocode", options);
  }
</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<link rel="stylesheet" href="../../styles.css">
<meta name="twitter:title" content="Cuong Nguyen - PAC-Bayes bounds for generalisation error">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://cnguyen10.github.io/posts/PAC-Bayes-bounds/data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Cuong Nguyen</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html" rel="" target=""><i class="bi bi-pencil-square" role="img">
</i> 
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target=""><i class="bi bi-person-circle" role="img">
</i> 
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-more" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">More</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-more">    
        <li>
    <a class="dropdown-item" href="../../teaching.html" rel="" target="">
 <span class="dropdown-text">Teaching</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../publication.html" rel="" target="">
 <span class="dropdown-text">Publication</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#auxillary-lemmas" id="toc-auxillary-lemmas" class="nav-link active" data-scroll-target="#auxillary-lemmas"><span class="header-section-number">1</span> Auxillary lemmas</a>
  <ul class="collapse">
  <li><a href="#change-of-measure-inequality-for-kullback-leibler-divergence" id="toc-change-of-measure-inequality-for-kullback-leibler-divergence" class="nav-link" data-scroll-target="#change-of-measure-inequality-for-kullback-leibler-divergence"><span class="header-section-number">1.1</span> Change of measure inequality for Kullback-Leibler divergence</a></li>
  <li><a href="#concentration-inequality" id="toc-concentration-inequality" class="nav-link" data-scroll-target="#concentration-inequality"><span class="header-section-number">1.2</span> Concentration inequality</a></li>
  </ul></li>
  <li><a href="#pac-bayes-bound" id="toc-pac-bayes-bound" class="nav-link" data-scroll-target="#pac-bayes-bound"><span class="header-section-number">2</span> PAC-Bayes bound</a></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion"><span class="header-section-number">3</span> Discussion</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">4</span> References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">PAC-Bayes bounds for generalisation error</h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Cuong Nguyen <a href="https://orcid.org/0000-0003-2672-6291" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="www.adelaide.edu.au">
            The University of Adelaide
            </a>
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">December 26, 2020</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p>Properly approaximately correct (PAC) learning is a part of <em>statistical machine learning</em> which has been a fundamental course for most of graduate programs in machine learning. Its main idea is to upper-bound the <em>true risk</em> (or generalisation error) by the <em>empirical risk</em> with certain confidence level. In other words, it is often written in the following form: <span class="math display">
\Pr (\text{true risk} \le \text{empirical risk} + r(m, \delta)) \ge 1 - \delta
</span> where <span class="math inline">\Pr(A)</span> is the probability of event <span class="math inline">A</span>, <span class="math inline">\delta \in (0, 1]</span> is the confidence parameter, and <span class="math inline">r(m, \delta)</span> – a function of <em>sample size</em> <span class="math inline">m</span> and the confidence parameter <span class="math inline">\delta</span> – is the <em>regularization</em> that is satisfied: <span class="math display">
\lim_{m \to +\infty} r(m, \delta) = 0.
</span> PAC-Bayes upper generalization bound is a kind of PAC learning. It was firstly proposed in 1999 <span class="citation" data-cites="mcallester1999pac">McAllester (<a href="#ref-mcallester1999pac" role="doc-biblioref">1999</a>)</span>, and has attracted much of research interest. There has been many subsequent improvements made to tighten further this classic PAC-Bayes bound or to extend it to more general loss functions. However, the classic PAC-Bayes theorem is still the backbone. In this post, I will show how to prove this interesting theorem.</p>
<section id="auxillary-lemmas" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="auxillary-lemmas"><span class="header-section-number">1</span> Auxillary lemmas</h2>
<p>To prove the classic PAC-Bayes theorem, we need two auxilliary lemmas shown below.</p>
<section id="change-of-measure-inequality-for-kullback-leibler-divergence" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="change-of-measure-inequality-for-kullback-leibler-divergence"><span class="header-section-number">1.1</span> Change of measure inequality for Kullback-Leibler divergence</h3>
<div id="lem-change-of-measure" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 1 </strong></span><span class="citation" data-cites="banerjee2006bayesian">(<a href="#ref-banerjee2006bayesian" role="doc-biblioref">Banerjee 2006</a> - Lemma 1)</span> For any measurable function <span class="math inline">\phi(h)</span> on a set of predictor under consideration <span class="math inline">\mathcal{H}</span>, and any distributions <span class="math inline">P</span> and <span class="math inline">Q</span> on <span class="math inline">\mathcal{H}</span>, the following inequality holds: <span class="math display">
\mathbb{E}_{Q} [\phi(h)] \le \mathrm{KL} [Q \Vert P] + \ln \mathbb{E}_{P} [\exp(\phi(h))].
</span> Further, <span class="math display">
\sup_{\phi} \mathbb{E}_{Q} [\phi(h)] - \ln \mathbb{E}_{P} [\exp(\phi(h))] = \mathrm{KL} [Q \Vert P].
</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>For any measurable function <span class="math inline">\phi(h)</span>, the following holds: <span class="math display">
\begin{aligned}
    \mathbb{E}_{Q} [\phi(h)] &amp; = \mathbb{E}_{Q} \left[ \ln \left( \exp(\phi(h)) \frac{Q(h)}{P(h)} \frac{P(h)}{Q(h)} \right) \right] \\
    &amp; = \mathrm{KL} [Q \Vert P] + \mathbb{E}_{Q} \left[ \ln \left( \exp(\phi(h)) \frac{P(h)}{Q(h)} \right) \right] \\
    &amp; \le \mathrm{KL} [Q \Vert P] + \ln \mathbb{E}_{Q} \left[ \exp(\phi(h)) \frac{P(h)}{Q(h)} \right] \\
    &amp; \qquad \text{(Jensen's inequality)}\\
    &amp; = \mathrm{KL} [Q \Vert P] + \ln \mathbb{E}_{P} \left[ \exp(\phi(h)) \right].
\end{aligned}
</span></p>
<p>For the second part of the lemma, we need to examine the equality condition of the Jensen’s inequality. Since <span class="math inline">\ln(x)</span> is a strictly concave function for <span class="math inline">x &gt; 0</span>, it follows that the equality holds when: <span class="math display">
\begin{aligned}
    \exp \left( \phi(h) \right) &amp; \frac{P(h)}{Q(h)} = 1 \\
    \iff \phi(h) &amp; = \ln \left[ \frac{Q(h)}{P(h)} \right].
\end{aligned}
</span> With this choice of <span class="math inline">\phi(h)</span>, we can verify that the equality does hold.</p>
<p>This completes the proof.</p>
</div>
</section>
<section id="concentration-inequality" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="concentration-inequality"><span class="header-section-number">1.2</span> Concentration inequality</h3>
<div id="lem-concentration-inequality" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 2 </strong></span><span class="citation" data-cites="shalev2014understanding">(<a href="#ref-shalev2014understanding" role="doc-biblioref">Shalev-Shwartz and Ben-David 2014</a> - Exercise 31.1)</span> Let <span class="math inline">X</span> be a random variable that satisfies: <span class="math inline">\mathrm{Pr} (X \ge \epsilon) \le e^{-2m \epsilon^{2}}</span>. Prove that <span class="math display">
\mathbb{E} \left[ e^{2(m - 1) X^{2}} \right] \le m.
</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Since the assumption is expressed in term of probability, while the conclusion is written in form of an expectation, what we need to do first is to try to present the expectation in terms of probability.</p>
<p>For simplicity, let <span class="math inline">Y = e^{2(m - 1) X^{2}}</span>. Since <span class="math inline">X \in [0, +\infty)</span>, then <span class="math inline">Y \in [1, +\infty)</span> and <span class="math inline">Y</span> can be presented as: <span class="math display">
Y = \int_{1}^{+\infty} \pmb{1}(Y \ge t) \, \mathrm{d}t + 1,
</span> where <span class="math inline">\pmb{1}(A)</span> is the indication function of event <span class="math inline">A</span>. Note that the integral above is the area of a rectangle with height as 1 and the width <span class="math inline">Y - 1</span>.</p>
<p>One important property of the indication function is that: <span class="math display">
\mathbb{E} \left[ \pmb{1}(Y \ge t) \right] = \mathrm{Pr}(Y \ge t).
</span> This allows to express the expectation of interest as: <span class="math display">
\begin{aligned}
\mathbb{E}[Y] &amp; = \mathbb{E} \left[ \int_{1}^{+\infty} \pmb{1}(Y \ge t) \, \mathrm{d}t \right] + 1 \\
&amp; = \int_{1}^{+\infty} \mathbb{E} [\pmb{1}(Y \ge t)] \, \mathrm{d}t + 1 \quad \text{(Fubini's theorem)} \\
&amp; = \int_{1}^{+\infty} \mathrm{Pr}(Y \ge t) \, \mathrm{d}t + 1.
\end{aligned}
</span> Or: <span class="math display">
\mathbb{E} \left[ e^{2(m - 1) X^{2}} \right] = \int_{1}^{+\infty} \mathrm{Pr}( e^{2(m - 1) X^{2}} \ge x) \, \mathrm{d}x + 1.
</span></p>
<p>We then make a change of variable from <span class="math inline">x</span> to <span class="math inline">\epsilon</span> to utilize the given inequality in the assumption. Let’s define: <span class="math display">
x = e^{2(m - 1) \epsilon^{2}}.
</span> Since <span class="math inline">\epsilon</span> is assumed to be non-negative, we can express it as: <span class="math display">
\epsilon = \sqrt{\frac{\ln x}{2(m - 1)}},
</span> and: <span class="math display">
\mathrm{d}x = 4(m - 1) \epsilon \, e^{2(m - 1) \epsilon^{2}} \, \mathrm{d} \epsilon.
</span></p>
<p>The expectation of interest can, therefore, be written as: <span class="math display">
\begin{aligned}
    \mathbb{E} \left[ e^{2(m - 1) X^{2}} \right] &amp; = \int_{0}^{+\infty} \mathrm{Pr} \left( e^{2(m - 1) X^{2}} \ge e^{2(m - 1) \epsilon^{2}} \right) 4(m - 1) \epsilon \, e^{2(m - 1) \epsilon^{2}} \, \mathrm{d} \epsilon  + 1\\
    &amp; = \int_{0}^{+\infty} \mathrm{Pr} \underbrace{\left( X \ge \epsilon \right)}_{\le e^{-2m\epsilon^{2}}} 4(m - 1) \epsilon \, e^{2(m - 1) \epsilon^{2}} \, \mathrm{d} \epsilon + 1\\
    &amp; \le 4(m - 1) \int_{0}^{+\infty} \epsilon \, e^{-2 \epsilon^{2}} \, \mathrm{d} \epsilon + 1 = m.
\end{aligned}
</span></p>
</div>
</section>
</section>
<section id="pac-bayes-bound" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="pac-bayes-bound"><span class="header-section-number">2</span> PAC-Bayes bound</h2>
<div id="thm-pac-bayes-bound" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 </strong></span>Let <span class="math inline">D</span> be an arbitrary distribution over an example domain <span class="math inline">Z</span>. Let <span class="math inline">\mathcal{H}</span> be a hypothesis class, <span class="math inline">\ell: \mathcal{H} \times Z \to [0, 1]</span> be a loss function, <span class="math inline">\pi</span> be a prior distribution over <span class="math inline">\mathcal{H}</span>, and <span class="math inline">\delta \in (0, 1]</span>. If <span class="math inline">S = \{z_j\}_{j=1}^{m}</span> is an i.i.d. training set sampled according to <span class="math inline">D</span>, then for any “posterior” <span class="math inline">Q</span> over <span class="math inline">\mathcal{H}</span>, the following holds: <span class="math display">
\mathrm{Pr} \left( \mathbb{E}_{z_{j} \sim D} \mathbb{E}_{h \sim Q} \left[ \ell(h, z_{j}) \right] \le \mathbb{E}_{z_{j} \sim S} \mathbb{E}_{h \sim Q} \left[ \ell(h, z_{j}) \right] + \sqrt{\frac{\mathrm{KL} [Q \Vert \pi] + \frac{\ln m}{\delta}}{2(m - 1)}} \right) \ge 1 - \delta.
</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>We define some notations to ease the proving: - <span class="math inline">L = \mathbb{E}_{z_{j} \sim D} \left[ \ell(h, z_{j}) \right]</span> - <span class="math inline">\hat{L} = \mathbb{E}_{z_{j} \sim S} \left[ \ell(h, z_{j}) \right] = \frac{1}{m} \sum_{j=1}^{m} \ell(h, z_{j})</span> - <span class="math inline">\Delta L = L - \hat{L}</span></p>
<p>Applying <a href="#lem-change-of-measure">Lemma&nbsp;1</a> with <span class="math inline">P(h) = \pi (h)</span> and <span class="math inline">\phi(h) = 2(m - 1) (\Delta L)^{2}</span> gives: <span id="eq-lower-bound-log_expect"><span class="math display">
2(m - 1) \mathbb{E}_{Q} \left[ (\Delta L)^{2} \right] - \mathrm{KL} [Q \Vert \pi] \le \textcolor{purple}{\ln \mathbb{E}_{\pi} \left[\exp \left( 2(m - 1) (\Delta L)^{2} \right) \right]}.
\tag{1}</span></span></p>
<p>We upper-bound the last term in the RHS (highlighted in <span style="color: purple;">purple</span> color) by <a href="#lem-concentration-inequality">Lemma&nbsp;2</a>. To do that, we consider the empirical loss on each observable data point <span class="math inline">l(h, z_{j})</span> as a random variable in <span class="math inline">[0, 1]</span> with true and empirical means <span class="math inline">L</span> and <span class="math inline">\hat{L}</span>, respectively. Following the Hoeffding’s inequality gives: <span class="math display">
\begin{aligned}
\mathrm{Pr} \left( \Delta L \ge \epsilon \right) &amp; = \mathrm{Pr} \left( L - \hat{L} \ge \epsilon \right)\\
&amp; \le \mathrm{Pr} \left( | L - \hat{L} | \ge \epsilon \right)\\
&amp; \le \exp(-2m \epsilon^{2}), \quad \epsilon \ge 0.
\end{aligned}
</span> According to <a href="#lem-concentration-inequality">Lemma&nbsp;2</a>, this implies: <span class="math display">
\mathbb{E}_{S} \left[\exp \left( 2(m - 1) (\Delta L)^{2} \right) \right] \le m.
</span> Taking the expectation w.r.t. <span class="math inline">h \sim \pi(h)</span> on both sides and applying Fubini’s theorem (to interchange the 2 expectations) gives: <span class="math display">
\begin{aligned}
&amp; \mathbb{E}_{S} \mathbb{E}_{\pi} \left[\exp \left( 2(m - 1) (\Delta L)^{2} \right) \right] \le \mathbb{E}_{\pi} \left[ m \right] = m\\
&amp; \implies \ln \mathbb{E}_{S} \mathbb{E}_{\pi} \left[\exp \left( 2(m - 1) (\Delta L)^{2} \right) \right] \le \ln m\\
&amp; \implies \mathbb{E}_{S} \textcolor{purple}{\ln \mathbb{E}_{\pi} \left[\exp \left( 2(m - 1) (\Delta L)^{2} \right) \right]} \le \ln m.
\end{aligned}
</span> Note that the last implication is due to Jensen’s inequality.</p>
<p>We then apply Markov’s inequality for the term highlighted in <span style="color: purple;">purple</span>: <span class="math display">
\begin{aligned}
\mathrm{Pr} \left( \textcolor{purple}{\ln \mathbb{E}_{\pi} \left[\exp \left( 2(m - 1) (\Delta L)^{2} \right) \right]} \ge \varepsilon \right) &amp; \le \frac{\mathbb{E}_{S} \textcolor{purple}{\ln \mathbb{E}_{\pi} \left[\exp \left( 2(m - 1) (\Delta L)^{2} \right) \right]}}{\varepsilon} \\
&amp; \le \frac{\ln m}{\varepsilon}.
\end{aligned}
</span></p>
<p>This implies: <span id="eq-bound_log_expect_prob"><span class="math display">
\mathrm{Pr} \left( \textcolor{purple}{\ln \mathbb{E}_{\pi} \left[\exp \left( 2(m - 1) (\Delta L)^{2} \right) \right]} \le \varepsilon \right) \ge 1 - \frac{\ln m}{\varepsilon}.
\tag{2}</span></span></p>
<p>Combining the results in <a href="#eq-lower-bound-log_expect">Equation&nbsp;1</a> and <a href="#eq-bound_log_expect_prob">Equation&nbsp;2</a> gives: <span class="math display">
\mathrm{Pr} \left( 2(m - 1) \mathbb{E}_{Q} \left[ (\Delta L)^{2} \right] - \mathrm{KL} [Q \Vert \pi] \le \varepsilon \right) \ge 1 - \frac{\ln m}{\varepsilon}.
</span></p>
<p>This is equivalent to: <span id="eq-almost-done"><span class="math display">
\mathrm{Pr} \left( \mathbb{E}_{Q} \left[ (\Delta L)^{2} \right] \le \frac{\mathrm{KL} [Q \Vert \pi] + \varepsilon}{2(m - 1)} \right) \ge 1 - \frac{\ln m}{\varepsilon}.
\tag{3}</span></span></p>
<p>Note that squared function is a strictly concave function, resulting in: <span class="math display">
\mathbb{E}_{Q} \left[ (\Delta L)^{2} \right] \ge \left( \mathbb{E}_{Q} \left[ \Delta L \right] \right)^{2}.
</span></p>
<p>Hence, <a href="#eq-almost-done">Equation&nbsp;3</a> can be written as: <span class="math display">
\mathrm{Pr} \left( \mathbb{E}_{Q} \left[ \Delta L \right] \le \sqrt{\frac{\mathrm{KL} [Q \Vert \pi] + \varepsilon}{2(m - 1)}} \right) \ge 1 - \frac{\ln m}{\varepsilon}.
</span></p>
<p>Seting <span class="math inline">\delta = \frac{\ln m}{\varepsilon}</span>, and expanding <span class="math inline">\Delta L</span> according to its definition complete the proof.</p>
</div>
</section>
<section id="discussion" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="discussion"><span class="header-section-number">3</span> Discussion</h2>
<p>AFAIK, the result in <a href="#thm-pac-bayes-bound">Theorem&nbsp;1</a> is a seminal PAC-Bayes bound in the literature of PAC learning. Readers could refer subsequent derivations of tighter PAC-Bayes bounds developed later.</p>
</section>
<section id="references" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="references"><span class="header-section-number">4</span> References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-banerjee2006bayesian" class="csl-entry" role="listitem">
Banerjee, Arindam. 2006. <span>“On Bayesian Bounds.”</span> In <em>International Conference on Machine Learning</em>, 81–88.
</div>
<div id="ref-mcallester1999pac" class="csl-entry" role="listitem">
McAllester, David A. 1999. <span>“PAC-Bayesian Model Averaging.”</span> In <em>Conference on Computational Learning Theory</em>, 164–70.
</div>
<div id="ref-shalev2014understanding" class="csl-entry" role="listitem">
Shalev-Shwartz, Shai, and Shai Ben-David. 2014. <em>Understanding Machine Learning: From Theory to Algorithms</em>. Cambridge university press.
</div>
</div>


</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div id="quarto-reuse" class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></div></div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{nguyen2020,
  author = {Nguyen, Cuong},
  title = {PAC-Bayes Bounds for Generalisation Error},
  date = {2020-12-26},
  url = {https://cnguyen10.github.io/posts/PAC-Bayes-bounds},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-nguyen2020" class="csl-entry quarto-appendix-citeas" role="listitem">
Nguyen, Cuong. 2020. <span>“PAC-Bayes Bounds for Generalisation
Error.”</span> December 26, 2020. <a href="https://cnguyen10.github.io/posts/PAC-Bayes-bounds">https://cnguyen10.github.io/posts/PAC-Bayes-bounds</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>